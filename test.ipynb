{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDL</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>135</td>\n",
       "      <td>172</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>65</td>\n",
       "      <td>146</td>\n",
       "      <td>194</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>75</td>\n",
       "      <td>118</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>95</td>\n",
       "      <td>131</td>\n",
       "      <td>180</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>121</td>\n",
       "      <td>155</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LDL  weight(kg)  systolic  Cholesterol  ALT  Gtp  triglyceride  \\\n",
       "id                                                                   \n",
       "0    75          60       135          172   25   27           300   \n",
       "1   126          65       146          194   23   37            55   \n",
       "2    93          75       118          178   31   53           197   \n",
       "3   102          95       131          180   27   30           203   \n",
       "4    93          60       121          155   13   17            87   \n",
       "\n",
       "    Urine protein  dental caries  height(cm)  smoking  \n",
       "id                                                     \n",
       "0               1              0         165        1  \n",
       "1               1              1         165        0  \n",
       "2               1              0         170        1  \n",
       "3               1              1         180        0  \n",
       "4               1              0         165        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('newdata.csv', index_col=[0])\n",
    "df.index.name = 'id'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engenering using(polynomil features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LDL', 'weight(kg)', 'systolic', 'Cholesterol', 'ALT', 'Gtp',\n",
      "       'triglyceride', 'Urine protein', 'dental caries', 'height(cm)',\n",
      "       'smoking'],\n",
      "      dtype='object')\n",
      "     LDL  weight(kg)  systolic  Cholesterol   ALT   Gtp  triglyceride  \\\n",
      "0   75.0        60.0     135.0        172.0  25.0  27.0         300.0   \n",
      "1  126.0        65.0     146.0        194.0  23.0  37.0          55.0   \n",
      "2   93.0        75.0     118.0        178.0  31.0  53.0         197.0   \n",
      "3  102.0        95.0     131.0        180.0  27.0  30.0         203.0   \n",
      "4   93.0        60.0     121.0        155.0  13.0  17.0          87.0   \n",
      "\n",
      "   Urine protein  dental caries  height(cm)  ...  triglyceride^2  \\\n",
      "0            1.0            0.0       165.0  ...         90000.0   \n",
      "1            1.0            1.0       165.0  ...          3025.0   \n",
      "2            1.0            0.0       170.0  ...         38809.0   \n",
      "3            1.0            1.0       180.0  ...         41209.0   \n",
      "4            1.0            0.0       165.0  ...          7569.0   \n",
      "\n",
      "   triglyceride Urine protein  triglyceride dental caries  \\\n",
      "0                       300.0                         0.0   \n",
      "1                        55.0                        55.0   \n",
      "2                       197.0                         0.0   \n",
      "3                       203.0                       203.0   \n",
      "4                        87.0                         0.0   \n",
      "\n",
      "   triglyceride height(cm)  Urine protein^2  Urine protein dental caries  \\\n",
      "0                  49500.0              1.0                          0.0   \n",
      "1                   9075.0              1.0                          1.0   \n",
      "2                  33490.0              1.0                          0.0   \n",
      "3                  36540.0              1.0                          1.0   \n",
      "4                  14355.0              1.0                          0.0   \n",
      "\n",
      "   Urine protein height(cm)  dental caries^2  dental caries height(cm)  \\\n",
      "0                     165.0              0.0                       0.0   \n",
      "1                     165.0              1.0                     165.0   \n",
      "2                     170.0              0.0                       0.0   \n",
      "3                     180.0              1.0                     180.0   \n",
      "4                     165.0              0.0                       0.0   \n",
      "\n",
      "   height(cm)^2  \n",
      "0       27225.0  \n",
      "1       27225.0  \n",
      "2       28900.0  \n",
      "3       32400.0  \n",
      "4       27225.0  \n",
      "\n",
      "[5 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trans = PolynomialFeatures(degree=2, include_bias = False)\n",
    "print(df.columns)\n",
    "Y=df['smoking']\n",
    "\n",
    "df.drop('smoking',axis=1 , inplace =True) \n",
    "\n",
    "data = trans.fit_transform(np.array(df)) # bta5od np array\n",
    "feature_names = df.columns  # Original feature, names mn gher el smoking\n",
    "\n",
    "# Use get_feature_names_out method to get feature names for the polynomial features\n",
    "poly_feature_names = trans.get_feature_names_out(input_features=feature_names)# model\n",
    "feature_index_mapping = {i: name for i, name in enumerate(poly_feature_names)}\n",
    "# Access the feature names for each column of the transformed array\n",
    "column_headers = [feature_index_mapping[i] for i in range(data.shape[1])]# shape 1 3dd el columns\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = column_headers\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose best 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Feature Names: Index(['LDL', 'weight(kg)', 'systolic', 'Cholesterol', 'ALT', 'Gtp',\n",
      "       'triglyceride', 'Urine protein', 'dental caries', 'height(cm)', 'LDL^2',\n",
      "       'LDL weight(kg)', 'LDL systolic', 'LDL Cholesterol', 'LDL ALT',\n",
      "       'LDL Gtp', 'LDL triglyceride', 'LDL Urine protein', 'LDL dental caries',\n",
      "       'LDL height(cm)', 'weight(kg)^2', 'weight(kg) systolic',\n",
      "       'weight(kg) Cholesterol', 'weight(kg) ALT', 'weight(kg) Gtp',\n",
      "       'weight(kg) triglyceride', 'weight(kg) Urine protein',\n",
      "       'weight(kg) dental caries', 'weight(kg) height(cm)', 'systolic^2',\n",
      "       'systolic Cholesterol', 'systolic ALT', 'systolic Gtp',\n",
      "       'systolic triglyceride', 'systolic Urine protein',\n",
      "       'systolic dental caries', 'systolic height(cm)', 'Cholesterol^2',\n",
      "       'Cholesterol ALT', 'Cholesterol Gtp', 'Cholesterol triglyceride',\n",
      "       'Cholesterol Urine protein', 'Cholesterol dental caries',\n",
      "       'Cholesterol height(cm)', 'ALT^2', 'ALT Gtp', 'ALT triglyceride',\n",
      "       'ALT Urine protein', 'ALT dental caries', 'ALT height(cm)', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp Urine protein', 'Gtp dental caries',\n",
      "       'Gtp height(cm)', 'triglyceride^2', 'triglyceride Urine protein',\n",
      "       'triglyceride dental caries', 'triglyceride height(cm)',\n",
      "       'Urine protein^2', 'Urine protein dental caries',\n",
      "       'Urine protein height(cm)', 'dental caries^2',\n",
      "       'dental caries height(cm)', 'height(cm)^2'],\n",
      "      dtype='object')\n",
      "Selected Feature Names: Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y = Y # smoking\n",
    "X = df \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "column_names = X.columns # asamy columns\n",
    "\n",
    "df = pd.DataFrame(X, columns=column_names)\n",
    "\n",
    "# Use SelectKBest with chi2 to select the top features\n",
    "k_best = 10  # Number of top features to select\n",
    "chi2_features = SelectKBest(chi2, k=k_best) # return object\n",
    "\n",
    "X_kbest_features = chi2_features.fit_transform(X, y) # ab3tlo data\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = chi2_features.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = df.columns[selected_feature_indices]\n",
    "\n",
    "print(\"Original Feature Names:\", df.columns)\n",
    "print(\"Selected Feature Names:\", selected_feature_names)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y\n",
    "x = df[selected_feature_names]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization using standard scaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: smoking, dtype: int64\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = X_train\n",
    "t = y_train\n",
    "col = data\n",
    "# Assuming 'df' is your DataFrame\n",
    "# print(col)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_z_scaled = pd.DataFrame(scaler.fit_transform(col), columns=col.columns) # minus mean / standard div\n",
    "# 3yzen nlz2 feature m3 target\n",
    "df_z_scaled.reset_index(drop=True, inplace=True)\n",
    "t.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#  now we remove the outliers\n",
    "df_z_scaled['smoking'] = t\n",
    "print(df_z_scaled['smoking'].head(5))\n",
    "cat, numerical = [], []\n",
    "for col in df_z_scaled.columns:\n",
    "    if df_z_scaled[col].nunique() > 10:\n",
    "        numerical.append(col)\n",
    "    else:\n",
    "        cat.append(col)\n",
    "for col in numerical:\n",
    "    Q1 = df_z_scaled[col].quantile(0.25)\n",
    "    Q3 = df_z_scaled[col].quantile(0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5*IQR\n",
    "    upper = Q3 + 1.5*IQR\n",
    "\n",
    "# Create arrays of Boolean values indicating the outlier rows\n",
    "    upper_array = np.where(df_z_scaled[col] >= upper)[0]\n",
    "    lower_array = np.where(df_z_scaled[col] <= lower)[0]\n",
    "\n",
    "    # Removing the outliers\n",
    "    df_z_scaled.drop(index=upper_array, inplace=True, errors='ignore')\n",
    "    df_z_scaled.drop(index=lower_array, inplace=True,  errors='ignore')\n",
    "\n",
    "\n",
    "print(df_z_scaled.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = y_val\n",
    "col = X_val\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_val_scaled = pd.DataFrame(scaler.fit_transform(col), columns=col.columns)\n",
    "df_val_scaled.reset_index(drop=True, inplace=True)\n",
    "tv.reset_index(drop=True, inplace=True)\n",
    "#  now we remove the outliers\n",
    "\n",
    "data_val = trans.fit_transform(np.array(df_val_scaled))\n",
    "feature_names = df_val_scaled.columns  # Original feature names\n",
    "\n",
    "# Use get_feature_names_out method to get feature names for the polynomial features\n",
    "poly_feature_names = trans.get_feature_names_out(input_features=feature_names)\n",
    "\n",
    "# Create a dictionary to map column indices to feature names\n",
    "feature_index_mapping = {i: name for i, name in enumerate(poly_feature_names)}\n",
    "\n",
    "# Access the feature names for each column of the transformed array\n",
    "column_headers = [feature_index_mapping[i] for i in range(df_val_scaled.shape[1])]\n",
    "\n",
    "\n",
    "df_val_scaled = pd.DataFrame(df_val_scaled)\n",
    "df_val_scaled.columns = column_headers\n",
    "\n",
    "df_val_scaled['smoking'] = tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_z_scaled['smoking']\n",
    "df_z_scaled.drop('smoking', axis = 1, inplace=True)\n",
    "Y_validation = df_val_scaled['smoking']\n",
    "df_val_scaled.drop(\"smoking\",axis =1 ,inplace =True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.6321319435723555\n",
      "Ensemble Accuracy: 0.6616015739461677\n",
      "Ensemble Accuracy: 0.6892293524216166\n",
      "Ensemble Accuracy: 0.7107873916865503\n",
      "Ensemble Accuracy: 0.7250198836284483\n",
      "Ensemble Accuracy: 0.7300012558081125\n",
      "Ensemble Accuracy: 0.7305035790531207\n",
      "{'n_trees': 128}\n",
      "0.7305035790531207\n"
     ]
    }
   ],
   "source": [
    "# Set the number of trees in the ensemble\n",
    "# e7na dlw2t sh8alen b df_val_scaled w df_z_scaled\n",
    "best_params = {}\n",
    "best_accuracy = -1\n",
    "    \n",
    "param_ranges = {\n",
    "        'n_trees': [2,4,8,16,32,64,128]\n",
    "        }\n",
    "\n",
    "\n",
    "# num_trees = 64\n",
    "# for _ in range(n_iter):\n",
    "#         params = {param: np.random.choice(values) for param, values in param_ranges.items()}\n",
    "for num in param_ranges['n_trees']:\n",
    "    num_trees = num\n",
    "# Create an array to store individual decision trees\n",
    "    trees = []\n",
    "    # y_train = df_z_scaled['smoking']\n",
    "    # df_z_scaled.drop('smoking', axis = 1, inplace=True)\n",
    "    #print(df_z_scaled.columns)\n",
    "    #print(df_val_scaled.columns)\n",
    "    for _ in range(num_trees):\n",
    "        # Bootstrap sampling: randomly sample with replacement\n",
    "        indices = np.random.choice(len(df_z_scaled), size=len(df_z_scaled), replace=True)\n",
    "        X_bootstrapped, y_bootstrapped = df_z_scaled.iloc[indices], y_train.iloc[indices]\n",
    "\n",
    "        # Train a decision tree on the bootstrapped dataset\n",
    "        tree = DecisionTreeClassifier()\n",
    "        tree.fit(X_bootstrapped, y_bootstrapped)\n",
    "\n",
    "        # Add the trained tree to the ensemble\n",
    "        trees.append(tree)\n",
    "\n",
    "    # Make predictions on the test set and aggregate the results\n",
    "    # Y_validation = df_val_scaled['smoking']\n",
    "    # df_val_scaled.drop(\"smoking\",axis =1 ,inplace =True )\n",
    "    predictions = np.array([tree.predict(df_val_scaled) for tree in trees])\n",
    "    ensemble_predictions = np.median(predictions, axis=0)  # You can use np.median() for classification\n",
    "\n",
    "    # Convert predictions to integer values for classification\n",
    "    ensemble_predictions = np.round(ensemble_predictions).astype(int) #3shan lw 3dd even median hytl3 0.5\n",
    "                                                                    # round will predict 1\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(Y_validation, ensemble_predictions) #vaid zy test 15%\n",
    "    print(\"Ensemble Accuracy:\", accuracy)\n",
    "    if(accuracy > best_accuracy):\n",
    "        best_accuracy =accuracy \n",
    "        best_params['n_trees'] = num\n",
    "\n",
    "print(best_params)\n",
    "print(best_accuracy)\n",
    "Bagging_best_parm=best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.alphas = []\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape # m \" number of samples\"\n",
    "        # Initialize weights for data points\n",
    "        w = np.ones(m) / m\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Create a weak learner (decision tree)\n",
    "            model = DecisionTreeClassifier()\n",
    "            # Fit the weak learner to the data with weighted samples\n",
    "            model.fit(X, y, sample_weight=w) #deaful all weight are equal\n",
    "            # Make predictions\n",
    "            predictions = model.predict(X)\n",
    "            # Calculate weighted error\n",
    "            weighted_error = np.sum(w * (predictions != y))\n",
    "            # Calculate alpha (weight of the weak learner)\n",
    "            alpha = 0.5 * np.log((1 - weighted_error) / max(weighted_error, 1e-10))\n",
    "            # Update weights\n",
    "            #print(predictions)\n",
    "            w *= np.exp(-alpha * y * predictions)# if true  --> mul *-alpha else mul alpha\n",
    "            w /= np.sum(w)\n",
    "            # Save alpha and the weak learner\n",
    "            self.alphas.append(alpha)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions using the weighted sum of weak learners\n",
    "        weighted_sum = sum(alpha * model.predict(X) for alpha, model in zip(self.alphas, self.models))#\n",
    "        # Apply sign function to get final predictions\n",
    "        predictions = np.sign(weighted_sum)# if >0 -- > 1 ,,,,,  asghr htrg3 -1 ,,,, 0 htrg3 0\n",
    "        #print(predictions,\" pr\")\n",
    "        return predictions.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search to ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Accuracy: 0.6172715475741973\n",
      "0.6172715475741973\n",
      "validation Accuracy: 0.6351040227719871\n",
      "0.6351040227719871\n",
      "validation Accuracy: 0.6389970279208004\n",
      "0.6389970279208004\n",
      "validation Accuracy: 0.6410900414416677\n",
      "0.6410900414416677\n",
      "validation Accuracy: 0.6435597973962912\n",
      "0.6435597973962912\n",
      "validation Accuracy: 0.6430156138808657\n",
      "validation Accuracy: 0.6367365733182636\n",
      "Best acc in boosting is : \n",
      " \n",
      "0.6435597973962912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params = {}\n",
    "best_accuracy = -1\n",
    "    \n",
    "param_ranges = {\n",
    "        'n_trees': [2,4,8,16,32,64,128],\n",
    "    }\n",
    "\n",
    "for num in param_ranges['n_trees']:\n",
    "    num_trees = num\n",
    "\n",
    "    boosting_model = AdaBoost(n_estimators=num_trees)\n",
    "    #print(X_train.shape)\n",
    "    boosting_model.fit(df_z_scaled, y_train.replace(0,-1))\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    predictions_train = boosting_model.predict(df_val_scaled)\n",
    "\n",
    "    # Calculate accuracy on the training data\n",
    "    accuracy_train = accuracy_score(Y_validation.replace(0,-1), predictions_train)\n",
    "    print(\"validation Accuracy:\", accuracy_train)\n",
    "    if(accuracy_train > best_accuracy) : \n",
    "        best_bossting_parm = num\n",
    "        best_accuracy = accuracy_train \n",
    "        best_params['n_trees'] = num \n",
    "        print(best_accuracy)\n",
    "print(\"Best acc in boosting is : \\n \")\n",
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "# Calculate Entropy\n",
    "def entropy(y):\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist/len(y)\n",
    "    return - np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "# Create Node\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "    \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "        \n",
    "\n",
    "#Decision Tree\n",
    "class DecissionTree:\n",
    "    import numpy as np\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None, max_features='auto'):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None\n",
    "        self.max_features = max_features\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.cols = list(X.columns)\n",
    "        self.root = self.grow_tree(X, y)\n",
    "        \n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        \n",
    "        df = X.copy()\n",
    "        df['smoking'] = y\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        \n",
    "        # stopping criteria\n",
    "        if (depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split):\n",
    "            leaf_value = self.most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        \n",
    "        # array of random columns in Dataset\n",
    "        \n",
    "        data = self.feature_sampling(X, self.max_features)\n",
    "               \n",
    "        feats_idxs = list(data.columns)\n",
    "                        \n",
    "        best_feat, best_thresh = self.best_criteria(X, y.tolist(), feats_idxs)\n",
    "        \n",
    "        left_df, right_df = df[df[best_feat]<=best_thresh].copy(), df[df[best_feat]>best_thresh].copy() \n",
    "      \n",
    "        left = self.grow_tree(left_df.drop('smoking', axis=1), left_df['smoking'].values, depth+1)\n",
    "        right = self.grow_tree(right_df.drop('smoking', axis=1), right_df['smoking'].values, depth+1)\n",
    "        \n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "        \n",
    "    def best_criteria(self, X, y, feats_idxs):\n",
    "        import numpy as np\n",
    "\n",
    "        best_gain = -1\n",
    "        split_idx, split_tresh = None, None\n",
    "        \n",
    "        X = X.to_numpy()\n",
    "        \n",
    "        for feats_idx in feats_idxs:\n",
    "            \n",
    "            index = int(self.cols.index(feats_idx))\n",
    "            \n",
    "            df = pd.DataFrame(X[:, index], columns=['X_col'])\n",
    "            df['y'] = y\n",
    "            df = df.sort_values(by=['X_col'], ascending=True)\n",
    "            \n",
    "            X_col_2 = df.X_col\n",
    "            y_2 = df.y\n",
    "                        \n",
    "            X_col_2 = X_col_2.to_numpy()\n",
    "            y_2 = y_2.to_numpy()\n",
    "            \n",
    "            for val in X_col_2:\n",
    "                gain = self.information_gain(y_2, X_col_2, val)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feats_idx\n",
    "                    split_tresh = val\n",
    "        \n",
    "        return split_idx, split_tresh\n",
    "    \n",
    "    def information_gain(self, y, X_col, thresh):\n",
    "        import numpy as np\n",
    "\n",
    "        parent_entropy = entropy(y)\n",
    "        \n",
    "        left, right = self.split(X_col, thresh)\n",
    "\n",
    "        if len(left) == 0 or len(right) == 0:\n",
    "            return 0\n",
    "        \n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left), len(right)\n",
    "        e_l, e_r = entropy(y[left]), entropy(y[right])\n",
    "        \n",
    "        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "        \n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "    \n",
    "    def split(self, X_col, split_tresh):\n",
    "        \n",
    "        left_idxs = np.argwhere(X_col <= split_tresh).flatten()\n",
    "        right_idxs = np.argwhere(X_col > split_tresh).flatten()\n",
    "\n",
    "        return left_idxs, right_idxs\n",
    "    \n",
    "    def most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "    \n",
    "    def predict(self, X):\n",
    "        import numpy as np\n",
    "\n",
    "        X = X.to_numpy().tolist()\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        \n",
    "        index = int(self.cols.index(node.feature))\n",
    "\n",
    "        if x[index] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        \n",
    "        return self.traverse_tree(x, node.right)\n",
    "    \n",
    "    def feature_sampling(self, data, val):\n",
    "        if type(val) == int:\n",
    "            col = random.sample(data.columns.tolist()[:], val)\n",
    "            new_df = data[col]\n",
    "            return new_df\n",
    "        elif type(val) == float:\n",
    "            col = random.sample(data.columns.tolist()[:], int(val * data.shape[1]))\n",
    "            new_df = data[col]\n",
    "            return new_df\n",
    "        elif val == 'auto' or val == 'sqrt':\n",
    "            col = random.sample(data.columns.tolist()[:], int(math.sqrt(data.shape[1])))\n",
    "            new_df = data[col]\n",
    "            return new_df\n",
    "        elif val == 'log2':\n",
    "            col = random.sample(data.columns.tolist()[:], int(math.log2(data.shape[1])))\n",
    "            new_df = data[col]\n",
    "            return new_df\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "\n",
    "\n",
    "class randomforestclassifier:\n",
    "    def __init__(self, n_estimators=100, criterion='entropy', max_depth=None, min_samples_split=2, bootstrap=True, max_samples=None,\n",
    "                 max_features='auto'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.bootstrap = bootstrap\n",
    "        self.max_samples = max_samples\n",
    "        self.max_features = max_features\n",
    "        \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        dummy_data = X_train.copy()\n",
    "        dummy_data['smoking'] = y_train\n",
    "        \n",
    "        self.tree_list = []\n",
    "        print(dummy_data.columns)\n",
    "        for i in range(self.n_estimators):\n",
    "            \n",
    "            if self.bootstrap == True:\n",
    "                df = self.row_sampling(dummy_data, self.max_samples)\n",
    "            else:\n",
    "                df = dummy_data.copy()\n",
    "            # print(df.columns)\n",
    "            print(type(df))\n",
    "            tree = DecissionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split, max_features=self.max_features)\n",
    "            \n",
    "            tree.fit(df.drop('smoking', axis=1), df['smoking'])\n",
    "            \n",
    "\n",
    "\n",
    "            self.tree_list.append(tree)\n",
    "            \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        y_preds = np.empty((X_test.shape[0], len(self.tree_list)))\n",
    "        # Let each tree make a prediction on the data\n",
    "        for i, tree in enumerate(self.tree_list):\n",
    "            # Indices of the features that the tree has trained on\n",
    "            # idx = tree.feature_indices\n",
    "            # Make a prediction based on those features\n",
    "            prediction = tree.predict(X_test)\n",
    "            y_preds[:, i] = prediction\n",
    "        \n",
    "        y_pred = []\n",
    "        # For each sample\n",
    "        for sample_predictions in y_preds:\n",
    "            # Select the most common class prediction\n",
    "            y_pred.append(np.bincount(sample_predictions.astype('int')).argmax())\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, y_true=None, y_pred=None):\n",
    "        acc = np.sum(y_true == y_pred)/len(y_true)\n",
    "        return acc\n",
    "    \n",
    "    def row_sampling(self, data, val):\n",
    "        new_df = data.sample(n=val, random_state=42)\n",
    "        return new_df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "0.6714387374942442\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "0.7001548830005442\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      " the best parameters so far are : {'n_trees': 10, 'n_bootstrap': 8000, 'n_features': 5, 'dt_max_depth': 3, 'min_sample_split': 2}\n",
      "accuracy is: 0.7001548830005442\n"
     ]
    }
   ],
   "source": [
    "def random_search(x_t, y_t ,x_val ,y_val ,  n_iter):\n",
    "        best_params = {}\n",
    "        best_accuracy = -1\n",
    "\n",
    "        param_ranges = {\n",
    "            'n_trees': [4, 10, 16, 32, 64],\n",
    "            'n_bootstrap': [1024,2048,4096,8000],\n",
    "            'n_features':[2, 3, 4, 5],\n",
    "            'dt_max_depth': [2, 3, 7, 9],\n",
    "            'min_sample_split' : [2, 3, 5]\n",
    "        }\n",
    "\n",
    "        for _ in range(n_iter):\n",
    "            params = {param: np.random.choice(values) for param, values in param_ranges.items()}\n",
    "            n_estimators = params['n_trees']\n",
    "            max_samples = params['n_bootstrap']\n",
    "            max_features = params['n_features']\n",
    "            max_depth = params['dt_max_depth']\n",
    "            min_sample_split = params['min_sample_split']\n",
    "            # print(n_trees)\n",
    "            # Call the random forest algorithm\n",
    "            forest = randomforestclassifier( n_estimators=n_estimators, max_depth= max_depth,\n",
    "                 min_samples_split= min_sample_split, max_samples= max_samples,\n",
    "                 max_features= max_features\n",
    "            )\n",
    "            \n",
    "            forest.fit(x_t,y_t)\n",
    "            # Make predictions on validation set\n",
    "            predictions = forest.predict(x_val)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = forest.score(y_val, predictions)\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                print(best_accuracy)\n",
    "                best_params = params.copy()\n",
    "\n",
    "        return best_params, best_accuracy\n",
    "\n",
    "\n",
    "best_params, best_accuracy = random_search(df_z_scaled,y_train, df_val_scaled,y_val, 10)\n",
    "print(f' the best parameters so far are : {best_params}')\n",
    "print(f'accuracy is: {best_accuracy}')\n",
    "best_pram_of_randForest=best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize test data and test on all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = y_test\n",
    "col = X_test\n",
    "\n",
    "scaler = StandardScaler() # - mean / sd\n",
    "df_test_scaled = pd.DataFrame(scaler.fit_transform(col), columns=col.columns)\n",
    "df_test_scaled.reset_index(drop=True, inplace=True)\n",
    "tv.reset_index(drop=True, inplace=True)\n",
    "#  now we remove the outliers\n",
    "\n",
    "data_val = trans.fit_transform(np.array(df_test_scaled))\n",
    "feature_names = df_test_scaled.columns  # Original feature names\n",
    "\n",
    "# Use get_feature_names_out method to get feature names for the polynomial features\n",
    "poly_feature_names = trans.get_feature_names_out(input_features=feature_names)\n",
    "\n",
    "# Create a dictionary to map column indices to feature names\n",
    "feature_index_mapping = {i: name for i, name in enumerate(poly_feature_names)}\n",
    "\n",
    "# Access the feature names for each column of the transformed array\n",
    "column_headers = [feature_index_mapping[i] for i in range(df_test_scaled.shape[1])]\n",
    "\n",
    "\n",
    "df_test_scaled = pd.DataFrame(df_test_scaled)\n",
    "df_test_scaled.columns = column_headers\n",
    "\n",
    "df_test_scaled['smoking'] = tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_trees': 10, 'n_bootstrap': 8000, 'n_features': 5, 'dt_max_depth': 3, 'min_sample_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_set on bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_test_scaled.drop('smoking',axis=1,inplace=True)\n",
    "print(df_test_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble test bagging accuracy: 0.7293620227729404\n"
     ]
    }
   ],
   "source": [
    "trees = []\n",
    "for _ in range(Bagging_best_parm['n_trees']):\n",
    "    # Bootstrap sampling: randomly sample with replacement\n",
    "    indices = np.random.choice(len(df_z_scaled), size=len(df_z_scaled), replace=True)\n",
    "    X_bootstrapped, y_bootstrapped = df_z_scaled.iloc[indices], y_train.iloc[indices]\n",
    "\n",
    "    # Train a decision tree on the bootstrapped dataset\n",
    "    tree = DecisionTreeClassifier()\n",
    "    tree.fit(X_bootstrapped, y_bootstrapped)\n",
    "\n",
    "    # Add the trained tree to the ensemble\n",
    "    trees.append(tree)\n",
    "\n",
    "# Make predictions on the test set and aggregate the results\n",
    "# Y_validation = df_val_scaled['smoking']\n",
    "# df_val_scaled.drop(\"smoking\",axis =1 ,inplace =True )\n",
    "predictions = np.array([tree.predict(df_test_scaled) for tree in trees])\n",
    "ensemble_predictions = np.median(predictions, axis=0)  # You can use np.median() for classification\n",
    "\n",
    "# Convert predictions to integer values for classification\n",
    "ensemble_predictions = np.round(ensemble_predictions).astype(int) #3shan lw 3dd even median hytl3 0.5\n",
    "                                                                # round will predict 1\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions) #vaid zy test 15%\n",
    "print(\"Ensemble test bagging accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set on best parm of Bossting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation boost Accuracy on test : 0.6386470194239786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "boosting_model = AdaBoost(n_estimators=best_bossting_parm)\n",
    "#print(X_train.shape)\n",
    "boosting_model.fit(df_z_scaled, y_train.replace(0,-1))\n",
    "\n",
    "# Make predictions on the training data\n",
    "predictions_train = boosting_model.predict(df_test_scaled)\n",
    "\n",
    "# Calculate accuracy on the training data\n",
    "accuracy_train = accuracy_score(y_test.replace(0,-1), predictions_train)\n",
    "print(\"validation boost Accuracy on test :\", accuracy_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set on best parm of rand forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LDL triglyceride', 'weight(kg) triglyceride', 'systolic triglyceride',\n",
      "       'Cholesterol Gtp', 'Cholesterol triglyceride', 'Gtp^2',\n",
      "       'Gtp triglyceride', 'Gtp height(cm)', 'triglyceride^2',\n",
      "       'triglyceride height(cm)', 'smoking'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "accuracy of random forest on test set 0.7017330877427997\n"
     ]
    }
   ],
   "source": [
    "forest = randomforestclassifier( n_estimators=best_pram_of_randForest['n_trees'],\n",
    "                                 max_depth= best_pram_of_randForest['dt_max_depth'],\n",
    "    min_samples_split= best_pram_of_randForest['min_sample_split'],\n",
    "    max_samples= best_pram_of_randForest['n_bootstrap'],\n",
    "    max_features= best_pram_of_randForest['n_features']\n",
    ")\n",
    "\n",
    "forest.fit(df_z_scaled,y_train)\n",
    "# Make predictions on validation set\n",
    "predictions = forest.predict(df_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = forest.score(y_test, predictions)\n",
    "\n",
    "print(\"accuracy of random forest on test set\",accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
